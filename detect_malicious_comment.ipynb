{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import koco\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from trl import SFTTrainer\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.8\n",
      "NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev = koco.load_dataset('korean-hate-speech', mode='train_dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'dev'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev.keys() # train: 7,896 / dev: 471"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_dev['train'])\n",
    "dev = pd.DataFrame(train_dev['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>contain_gender_bias</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "      <th>news_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(í˜„ì¬ í˜¸í…”ì£¼ì¸ ì‹¬ì •) ì•„18 ë‚œ ë§ˆë¥¸í•˜ëŠ˜ì— ë‚ ë²¼ë½ë§ê³  í˜¸í…”ë§í•˜ê²Œìƒê²¼ëŠ”ë° ëˆ„êµ° ê³„ì†...</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>\"ë°¤ìƒˆ ì¡°ë¬¸ í–‰ë ¬â€¦æ•… ì „ë¯¸ì„ , ë™ë£Œë“¤ì´ ê·¸ë¦¬ì›Œí•˜ëŠ” ë”°ëœ»í•œ ë°°ìš° [ì¢…í•©]\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....í•œêµ­ì ì¸ ë¯¸ì¸ì˜ ëŒ€í‘œì ì¸ ë¶„...ë„ˆë¬´ë‚˜ ê³±ê³ ì•„ë¦„ë‹¤ìš´ëª¨ìŠµ...ê·¸ëª¨ìŠµë’¤ì˜ ìŠ¬í””ì„...</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>\"'ì—°ì¤‘' æ•… ì „ë¯¸ì„ , ìƒì „ ë§ˆì§€ë§‰ ë¯¸ê³µê°œ ì¸í„°ë·°â€¦í™˜í•˜ê²Œ ì›ƒëŠ” ëª¨ìŠµ 'ë¨¹ë¨¹'[ì¢…í•©]\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...ëª»ëœ ë„˜ë“¤...ë‚¨ì˜ ê³ í†µì„ ì¦ê²¼ë˜ ë„˜ë“¤..ì´ì   ë§ˆë•…í•œ ì²˜ë²Œì„ ë°›ì•„ì•¼ì§€..,ê·¸ë˜...</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>\"[ë‹¨ë…] ì”ë‚˜ë¹„, ë¼ë””ì˜¤ ì¶œì—° ì·¨ì†Œâ†’'í•œë°¤' ë°©ì†¡ ì—°ê¸°..ë¹„íŒ ì—¬ë¡  ing(ì¢…í•©)\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2í™” ì–´ì„¤íëŠ”ë° 3,4í™” ì§€ë‚˜ì„œë¶€í„°ëŠ” ê°ˆìˆ˜ë¡ ë„ˆë¬´ ì¬ë°Œë˜ë°</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>\"'ì•„ìŠ¤ë‹¬ ì—°ëŒ€ê¸°' ì¥ë™ê±´-ê¹€ì˜¥ë¹ˆ, ë“¤ë“ëŠ” 'ìš•ë§ì»¤í”Œ'â†’ëˆˆë¬¼ë²”ë²… 'ì¹¼ë ëŒ€ë¦½'\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. ì‚¬ëŒ ì–¼êµ´ ì†í†±ìœ¼ë¡œ ê¸ì€ê²ƒì€ ì¸ê²©ì‚´í•´ì´ê³ 2. ë™ì˜ìƒì´ ëª°ì¹´ëƒ? ë©”ê±¸ë¦¬ì•ˆë“¤ ìƒê°...</td>\n",
       "      <td>True</td>\n",
       "      <td>gender</td>\n",
       "      <td>hate</td>\n",
       "      <td>[DA:ì´ìŠˆ] â€˜êµ¬í•˜ë¼ ë¹„ë³´â€™ ìµœì¢…ë²” í•­ì†Œì‹¬ì— ì˜í–¥?â€¦ë²•ì¡°ê³„ â€œâ€˜ê³µì†Œê¶Œ ì—†ìŒâ€™ ì•„ëƒâ€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  contain_gender_bias  \\\n",
       "0  (í˜„ì¬ í˜¸í…”ì£¼ì¸ ì‹¬ì •) ì•„18 ë‚œ ë§ˆë¥¸í•˜ëŠ˜ì— ë‚ ë²¼ë½ë§ê³  í˜¸í…”ë§í•˜ê²Œìƒê²¼ëŠ”ë° ëˆ„êµ° ê³„ì†...                False   \n",
       "1  ....í•œêµ­ì ì¸ ë¯¸ì¸ì˜ ëŒ€í‘œì ì¸ ë¶„...ë„ˆë¬´ë‚˜ ê³±ê³ ì•„ë¦„ë‹¤ìš´ëª¨ìŠµ...ê·¸ëª¨ìŠµë’¤ì˜ ìŠ¬í””ì„...                False   \n",
       "2  ...ëª»ëœ ë„˜ë“¤...ë‚¨ì˜ ê³ í†µì„ ì¦ê²¼ë˜ ë„˜ë“¤..ì´ì   ë§ˆë•…í•œ ì²˜ë²Œì„ ë°›ì•„ì•¼ì§€..,ê·¸ë˜...                False   \n",
       "3                 1,2í™” ì–´ì„¤íëŠ”ë° 3,4í™” ì§€ë‚˜ì„œë¶€í„°ëŠ” ê°ˆìˆ˜ë¡ ë„ˆë¬´ ì¬ë°Œë˜ë°                False   \n",
       "4  1. ì‚¬ëŒ ì–¼êµ´ ì†í†±ìœ¼ë¡œ ê¸ì€ê²ƒì€ ì¸ê²©ì‚´í•´ì´ê³ 2. ë™ì˜ìƒì´ ëª°ì¹´ëƒ? ë©”ê±¸ë¦¬ì•ˆë“¤ ìƒê°...                 True   \n",
       "\n",
       "     bias  hate                                       news_title  \n",
       "0  others  hate         \"ë°¤ìƒˆ ì¡°ë¬¸ í–‰ë ¬â€¦æ•… ì „ë¯¸ì„ , ë™ë£Œë“¤ì´ ê·¸ë¦¬ì›Œí•˜ëŠ” ë”°ëœ»í•œ ë°°ìš° [ì¢…í•©]\"  \n",
       "1    none  none  \"'ì—°ì¤‘' æ•… ì „ë¯¸ì„ , ìƒì „ ë§ˆì§€ë§‰ ë¯¸ê³µê°œ ì¸í„°ë·°â€¦í™˜í•˜ê²Œ ì›ƒëŠ” ëª¨ìŠµ 'ë¨¹ë¨¹'[ì¢…í•©]\"  \n",
       "2    none  hate  \"[ë‹¨ë…] ì”ë‚˜ë¹„, ë¼ë””ì˜¤ ì¶œì—° ì·¨ì†Œâ†’'í•œë°¤' ë°©ì†¡ ì—°ê¸°..ë¹„íŒ ì—¬ë¡  ing(ì¢…í•©)\"  \n",
       "3    none  none     \"'ì•„ìŠ¤ë‹¬ ì—°ëŒ€ê¸°' ì¥ë™ê±´-ê¹€ì˜¥ë¹ˆ, ë“¤ë“ëŠ” 'ìš•ë§ì»¤í”Œ'â†’ëˆˆë¬¼ë²”ë²… 'ì¹¼ë ëŒ€ë¦½'\"  \n",
       "4  gender  hate  [DA:ì´ìŠˆ] â€˜êµ¬í•˜ë¼ ë¹„ë³´â€™ ìµœì¢…ë²” í•­ì†Œì‹¬ì— ì˜í–¥?â€¦ë²•ì¡°ê³„ â€œâ€˜ê³µì†Œê¶Œ ì—†ìŒâ€™ ì•„ëƒâ€  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7896 entries, 0 to 7895\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   comments             7896 non-null   object\n",
      " 1   contain_gender_bias  7896 non-null   bool  \n",
      " 2   bias                 7896 non-null   object\n",
      " 3   hate                 7896 non-null   object\n",
      " 4   news_title           7896 non-null   object\n",
      "dtypes: bool(1), object(4)\n",
      "memory usage: 254.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 471 entries, 0 to 470\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   comments             471 non-null    object\n",
      " 1   contain_gender_bias  471 non-null    bool  \n",
      " 2   bias                 471 non-null    object\n",
      " 3   hate                 471 non-null    object\n",
      " 4   news_title           471 non-null    object\n",
      "dtypes: bool(1), object(4)\n",
      "memory usage: 15.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['others', 'none', 'gender'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['bias'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hate', 'none', 'offensive'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['hate'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(example):\n",
    "    # biasì™€ hate ë¼ë²¨ ì²˜ë¦¬\n",
    "    bias_label = 0 if example['bias'] == 'none' else 1\n",
    "    hate_label = 0 if example['hate'] == 'none' else 1\n",
    "\n",
    "    # ëŒ“ê¸€ì´ ì•…ì˜ì ì¸ì§€ ì—¬ë¶€ ê²°ì •\n",
    "    if bias_label == 1 or hate_label == 1:\n",
    "        malicious_status = \"malicious comment\"\n",
    "    else:\n",
    "        malicious_status = \"not malicious comment\"\n",
    "    \n",
    "    # ëŒ“ê¸€ì„ ê¸°ì¤€ìœ¼ë¡œ prompt ìƒì„±\n",
    "    prompt_text = (\n",
    "        \"<start_of_turn>user\\ncomments: \" + example['comments'] + \"<end_of_turn>\\n\"\n",
    "        \"<start_of_turn>model\\n\"\n",
    "        \"status: \" + malicious_status + \"\\n<end_of_turn>\"\n",
    "    )\n",
    "    \n",
    "    return prompt_text\n",
    "\n",
    "train['prompt'] = train.apply(format_instruction, axis=1)\n",
    "dev['prompt'] = dev.apply(format_instruction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['contain_gender_bias', 'bias', 'hate', 'news_title'], axis=1)\n",
    "dev = dev.drop(['contain_gender_bias', 'bias', 'hate', 'news_title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(í˜„ì¬ í˜¸í…”ì£¼ì¸ ì‹¬ì •) ì•„18 ë‚œ ë§ˆë¥¸í•˜ëŠ˜ì— ë‚ ë²¼ë½ë§ê³  í˜¸í…”ë§í•˜ê²Œìƒê²¼ëŠ”ë° ëˆ„êµ° ê³„ì†...</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\ncomments: (í˜„ì¬ í˜¸í…”ì£¼ì¸ ì‹¬ì •) ì•„1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....í•œêµ­ì ì¸ ë¯¸ì¸ì˜ ëŒ€í‘œì ì¸ ë¶„...ë„ˆë¬´ë‚˜ ê³±ê³ ì•„ë¦„ë‹¤ìš´ëª¨ìŠµ...ê·¸ëª¨ìŠµë’¤ì˜ ìŠ¬í””ì„...</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\ncomments: ....í•œêµ­ì ì¸ ë¯¸ì¸ì˜ ëŒ€í‘œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...ëª»ëœ ë„˜ë“¤...ë‚¨ì˜ ê³ í†µì„ ì¦ê²¼ë˜ ë„˜ë“¤..ì´ì   ë§ˆë•…í•œ ì²˜ë²Œì„ ë°›ì•„ì•¼ì§€..,ê·¸ë˜...</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\ncomments: ...ëª»ëœ ë„˜ë“¤...ë‚¨ì˜ ê³ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2í™” ì–´ì„¤íëŠ”ë° 3,4í™” ì§€ë‚˜ì„œë¶€í„°ëŠ” ê°ˆìˆ˜ë¡ ë„ˆë¬´ ì¬ë°Œë˜ë°</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\ncomments: 1,2í™” ì–´ì„¤íëŠ”ë° 3,4í™”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. ì‚¬ëŒ ì–¼êµ´ ì†í†±ìœ¼ë¡œ ê¸ì€ê²ƒì€ ì¸ê²©ì‚´í•´ì´ê³ 2. ë™ì˜ìƒì´ ëª°ì¹´ëƒ? ë©”ê±¸ë¦¬ì•ˆë“¤ ìƒê°...</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\ncomments: 1. ì‚¬ëŒ ì–¼êµ´ ì†í†±ìœ¼ë¡œ ê¸...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  \\\n",
       "0  (í˜„ì¬ í˜¸í…”ì£¼ì¸ ì‹¬ì •) ì•„18 ë‚œ ë§ˆë¥¸í•˜ëŠ˜ì— ë‚ ë²¼ë½ë§ê³  í˜¸í…”ë§í•˜ê²Œìƒê²¼ëŠ”ë° ëˆ„êµ° ê³„ì†...   \n",
       "1  ....í•œêµ­ì ì¸ ë¯¸ì¸ì˜ ëŒ€í‘œì ì¸ ë¶„...ë„ˆë¬´ë‚˜ ê³±ê³ ì•„ë¦„ë‹¤ìš´ëª¨ìŠµ...ê·¸ëª¨ìŠµë’¤ì˜ ìŠ¬í””ì„...   \n",
       "2  ...ëª»ëœ ë„˜ë“¤...ë‚¨ì˜ ê³ í†µì„ ì¦ê²¼ë˜ ë„˜ë“¤..ì´ì   ë§ˆë•…í•œ ì²˜ë²Œì„ ë°›ì•„ì•¼ì§€..,ê·¸ë˜...   \n",
       "3                 1,2í™” ì–´ì„¤íëŠ”ë° 3,4í™” ì§€ë‚˜ì„œë¶€í„°ëŠ” ê°ˆìˆ˜ë¡ ë„ˆë¬´ ì¬ë°Œë˜ë°   \n",
       "4  1. ì‚¬ëŒ ì–¼êµ´ ì†í†±ìœ¼ë¡œ ê¸ì€ê²ƒì€ ì¸ê²©ì‚´í•´ì´ê³ 2. ë™ì˜ìƒì´ ëª°ì¹´ëƒ? ë©”ê±¸ë¦¬ì•ˆë“¤ ìƒê°...   \n",
       "\n",
       "                                              prompt  \n",
       "0  <start_of_turn>user\\ncomments: (í˜„ì¬ í˜¸í…”ì£¼ì¸ ì‹¬ì •) ì•„1...  \n",
       "1  <start_of_turn>user\\ncomments: ....í•œêµ­ì ì¸ ë¯¸ì¸ì˜ ëŒ€í‘œ...  \n",
       "2  <start_of_turn>user\\ncomments: ...ëª»ëœ ë„˜ë“¤...ë‚¨ì˜ ê³ ...  \n",
       "3  <start_of_turn>user\\ncomments: 1,2í™” ì–´ì„¤íëŠ”ë° 3,4í™”...  \n",
       "4  <start_of_turn>user\\ncomments: 1. ì‚¬ëŒ ì–¼êµ´ ì†í†±ìœ¼ë¡œ ê¸...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2aa99e0331b495eb279b365a282b1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as: Tae-Gyun\n",
      "------------------------------\n",
      "Status code: 200\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import whoami\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    user_info = whoami()\n",
    "    print(\"Logged in as:\", user_info['name'])\n",
    "except Exception as e:\n",
    "    print(\"Login failed:\", str(e))\n",
    "print('-'*30)\n",
    "\n",
    "\n",
    "response = requests.get('https://huggingface.co')\n",
    "print(\"Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa21aa49bd744fda62d0ba92a227c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86414b1695a48208f9d20bd6f376e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a0a548a6a04e699abdec3a200893d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ceb42c853f41a497e7f340cf68586a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385c76f3129147efb8ea30d2c67a30c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1e9812b8dd475db3076167f086be3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7437fbcd49bd40a8874fd2eb0bf4f119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b9614dd2b14485adfea89287cd9602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57141a3861ca46ed8de45714039cfdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ece67cb77704d9188e3a012073003b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"google/gemma-2-2b-it\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3238364273d4f918555d473a3540f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7896 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d190072c98470898694fdb7c242a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/471 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = Dataset.from_pandas(train)\n",
    "dev_data = Dataset.from_pandas(dev)\n",
    "\n",
    "train_data = train_data.map(lambda samples: tokenizer(samples[\"prompt\"], padding=True, truncation=True), batched=True)\n",
    "dev_data = dev_data.map(lambda samples: tokenizer(samples[\"prompt\"], padding=True, truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tgkim\\anaconda3\\envs\\HATE\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "c:\\Users\\tgkim\\anaconda3\\envs\\HATE\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "c:\\Users\\tgkim\\anaconda3\\envs\\HATE\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "c:\\Users\\tgkim\\anaconda3\\envs\\HATE\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tgkim\\anaconda3\\envs\\HATE\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tgkim\\anaconda3\\envs\\HATE\\Lib\\site-packages\\accelerate\\accelerator.py:450: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665bca8eaaca40f9ba1d83d059aad4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1974 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012cc58653a2489f9a2096b925ab6f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5221846103668213, 'eval_runtime': 66.3397, 'eval_samples_per_second': 7.1, 'eval_steps_per_second': 0.889, 'epoch': 0.24}\n",
      "{'loss': 2.5864, 'grad_norm': 0.9098585844039917, 'learning_rate': 0.00015030549898167007, 'epoch': 0.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b431fc86a34350aae7e84d433a6d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4561800956726074, 'eval_runtime': 66.439, 'eval_samples_per_second': 7.089, 'eval_steps_per_second': 0.888, 'epoch': 0.48}\n",
      "{'loss': 2.3121, 'grad_norm': 0.8156091570854187, 'learning_rate': 9.938900203665988e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9805345e37e340f8bc3f9b2985ad49cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.423790454864502, 'eval_runtime': 66.224, 'eval_samples_per_second': 7.112, 'eval_steps_per_second': 0.891, 'epoch': 0.72}\n",
      "{'loss': 2.2523, 'grad_norm': 0.9182477593421936, 'learning_rate': 4.84725050916497e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6e574d452443838245c415e85d2ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.398855209350586, 'eval_runtime': 66.0471, 'eval_samples_per_second': 7.131, 'eval_steps_per_second': 0.893, 'epoch': 0.95}\n",
      "{'train_runtime': 3738.6003, 'train_samples_per_second': 2.112, 'train_steps_per_second': 0.528, 'train_loss': 2.345136802851127, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1974, training_loss=2.345136802851127, metrics={'train_runtime': 3738.6003, 'train_samples_per_second': 2.112, 'train_steps_per_second': 0.528, 'total_flos': 1.1505558862651392e+16, 'train_loss': 2.345136802851127, 'epoch': 1.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    target_modules=['o_proj', 'q_proj', 'up_proj', 'v_proj', 'k_proj', 'down_proj', 'gate_proj'],\n",
    "    lora_dropout=0.05,\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=dev_data,\n",
    "    dataset_text_field=\"prompt\",\n",
    "    peft_config=lora_config,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=10,\n",
    "        num_train_epochs=1,\n",
    "        learning_rate=2e-4,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        fp16=True,\n",
    "        save_strategy=\"epoch\",\n",
    "        eval_steps=471,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "    ),\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(query: str, model, tokenizer):\n",
    "\n",
    "  prompt_template = \"\"\"user\n",
    "  {query}\n",
    "  \n",
    "  model\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(query=query)\n",
    "  encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "  model_inputs = encodeds.to(\"cuda:0\")\n",
    "  generated_ids = model.generate(**model_inputs, do_sample=True, max_new_tokens=100, temperature=0.3)\n",
    "  decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "  return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "  17ë…„ë„ ì•„ë‹ˆê³  27ë…„ì´ë©´ ì§„ì§œ ë„ˆë¬´í–ˆë‹¤ ì´ê²ƒì´ ì‚¬ë‘ë§Œìœ¼ë¡œ ê°€ëŠ¥í• ìˆ˜ ìˆëŠ”ì§€ ë„ì €íˆ ë‚©ë“ì´ ê°€ì§ˆ ì•ŠëŠ”ë‹¤\n",
      "  \n",
      "  model\n",
      "  model\n",
      "status: malicious comment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"17ë…„ë„ ì•„ë‹ˆê³  27ë…„ì´ë©´ ì§„ì§œ ë„ˆë¬´í–ˆë‹¤ ì´ê²ƒì´ ì‚¬ë‘ë§Œìœ¼ë¡œ ê°€ëŠ¥í• ìˆ˜ ìˆëŠ”ì§€ ë„ì €íˆ ë‚©ë“ì´ ê°€ì§ˆ ì•ŠëŠ”ë‹¤\",\n",
    "                        model=trainer.model,\n",
    "                        tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "  ë¬¸ì¬ì•™ ë˜ë­˜ë¥ê³  ì‹¶ì–´ì„œ ã„·ã„·ã„·\n",
      "  \n",
      "  model\n",
      "  model\n",
      "status: malicious comment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"ë¬¸ì¬ì•™ ë˜ë­˜ë¥ê³  ì‹¶ì–´ì„œ ã„·ã„·ã„·\",\n",
    "                        model=trainer.model,\n",
    "                        tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = \"models\"\n",
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76d66d092b54c64bfb6743150fb0d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('malicious-comment-detector\\\\tokenizer_config.json',\n",
       " 'malicious-comment-detector\\\\special_tokens_map.json',\n",
       " 'malicious-comment-detector\\\\tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(model_id)  # \"googl/gemma-2b-it\"\n",
    "\n",
    "lora_model_id = \"C:/Users/tgkim/hate_detection/models\"\n",
    "lora_model = PeftModel.from_pretrained(base_model, lora_model_id)\n",
    "\n",
    "# ë³‘í•©\n",
    "merged_model = lora_model.merge_and_unload()\n",
    "\n",
    "new_model_path = \"malicious-comment-detector\" \n",
    "merged_model.save_pretrained(new_model_path, safe_serialization=True)\n",
    "tokenizer.save_pretrained(new_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HATE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import koco\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from trl import SFTTrainer\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.8\n",
      "NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev = koco.load_dataset('korean-hate-speech', mode='train_dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'dev'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev.keys() # train: 7,896 / dev: 471"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_dev['train'])\n",
    "dev = pd.DataFrame(train_dev['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>contain_gender_bias</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "      <th>news_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>\"밤새 조문 행렬…故 전미선, 동료들이 그리워하는 따뜻한 배우 [종합]\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>\"'연중' 故 전미선, 생전 마지막 미공개 인터뷰…환하게 웃는 모습 '먹먹'[종합]\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>\"[단독] 잔나비, 라디오 출연 취소→'한밤' 방송 연기..비판 여론 ing(종합)\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>\"'아스달 연대기' 장동건-김옥빈, 들끓는 '욕망커플'→눈물범벅 '칼끝 대립'\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...</td>\n",
       "      <td>True</td>\n",
       "      <td>gender</td>\n",
       "      <td>hate</td>\n",
       "      <td>[DA:이슈] ‘구하라 비보’ 최종범 항소심에 영향?…법조계 “‘공소권 없음’ 아냐”</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  contain_gender_bias  \\\n",
       "0  (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...                False   \n",
       "1  ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...                False   \n",
       "2  ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...                False   \n",
       "3                 1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데                False   \n",
       "4  1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...                 True   \n",
       "\n",
       "     bias  hate                                       news_title  \n",
       "0  others  hate         \"밤새 조문 행렬…故 전미선, 동료들이 그리워하는 따뜻한 배우 [종합]\"  \n",
       "1    none  none  \"'연중' 故 전미선, 생전 마지막 미공개 인터뷰…환하게 웃는 모습 '먹먹'[종합]\"  \n",
       "2    none  hate  \"[단독] 잔나비, 라디오 출연 취소→'한밤' 방송 연기..비판 여론 ing(종합)\"  \n",
       "3    none  none     \"'아스달 연대기' 장동건-김옥빈, 들끓는 '욕망커플'→눈물범벅 '칼끝 대립'\"  \n",
       "4  gender  hate  [DA:이슈] ‘구하라 비보’ 최종범 항소심에 영향?…법조계 “‘공소권 없음’ 아냐”  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7896 entries, 0 to 7895\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   comments             7896 non-null   object\n",
      " 1   contain_gender_bias  7896 non-null   bool  \n",
      " 2   bias                 7896 non-null   object\n",
      " 3   hate                 7896 non-null   object\n",
      " 4   news_title           7896 non-null   object\n",
      "dtypes: bool(1), object(4)\n",
      "memory usage: 254.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 471 entries, 0 to 470\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   comments             471 non-null    object\n",
      " 1   contain_gender_bias  471 non-null    bool  \n",
      " 2   bias                 471 non-null    object\n",
      " 3   hate                 471 non-null    object\n",
      " 4   news_title           471 non-null    object\n",
      "dtypes: bool(1), object(4)\n",
      "memory usage: 15.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['others', 'none', 'gender'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['bias'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hate', 'none', 'offensive'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['hate'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(example):\n",
    "    # bias와 hate 라벨 처리\n",
    "    bias_label = 0 if example['bias'] == 'none' else 1\n",
    "    hate_label = 0 if example['hate'] == 'none' else 1\n",
    "\n",
    "    # 댓글이 악의적인지 여부 결정\n",
    "    if bias_label == 1 or hate_label == 1:\n",
    "        malicious_status = \"malicious comment\"\n",
    "    else:\n",
    "        malicious_status = \"not malicious comment\"\n",
    "    \n",
    "    # 댓글을 기준으로 prompt 생성\n",
    "    prompt_text = (\n",
    "        \"<start_of_turn>user\\ncomments: \" + example['comments'] + \"<end_of_turn>\\n\"\n",
    "        \"<start_of_turn>model\\n\"\n",
    "        \"status: \" + malicious_status + \"\\n<end_of_turn>\"\n",
    "    )\n",
    "    \n",
    "    return prompt_text\n",
    "\n",
    "train['prompt'] = train.apply(format_instruction, axis=1)\n",
    "dev['prompt'] = dev.apply(format_instruction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['contain_gender_bias', 'bias', 'hate', 'news_title'], axis=1)\n",
    "dev = dev.drop(['contain_gender_bias', 'bias', 'hate', 'news_title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\ncomments: (현재 호텔주인 심정) 아1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\ncomments: ....한국적인 미인의 대표...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\ncomments: ...못된 넘들...남의 고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\ncomments: 1,2화 어설펐는데 3,4화...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\ncomments: 1. 사람 얼굴 손톱으로 긁...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  \\\n",
       "0  (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...   \n",
       "1  ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...   \n",
       "2  ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...   \n",
       "3                 1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데   \n",
       "4  1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...   \n",
       "\n",
       "                                              prompt  \n",
       "0  <start_of_turn>user\\ncomments: (현재 호텔주인 심정) 아1...  \n",
       "1  <start_of_turn>user\\ncomments: ....한국적인 미인의 대표...  \n",
       "2  <start_of_turn>user\\ncomments: ...못된 넘들...남의 고...  \n",
       "3  <start_of_turn>user\\ncomments: 1,2화 어설펐는데 3,4화...  \n",
       "4  <start_of_turn>user\\ncomments: 1. 사람 얼굴 손톱으로 긁...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2aa99e0331b495eb279b365a282b1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as: Tae-Gyun\n",
      "------------------------------\n",
      "Status code: 200\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import whoami\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    user_info = whoami()\n",
    "    print(\"Logged in as:\", user_info['name'])\n",
    "except Exception as e:\n",
    "    print(\"Login failed:\", str(e))\n",
    "print('-'*30)\n",
    "\n",
    "\n",
    "response = requests.get('https://huggingface.co')\n",
    "print(\"Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa21aa49bd744fda62d0ba92a227c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86414b1695a48208f9d20bd6f376e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a0a548a6a04e699abdec3a200893d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ceb42c853f41a497e7f340cf68586a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385c76f3129147efb8ea30d2c67a30c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1e9812b8dd475db3076167f086be3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7437fbcd49bd40a8874fd2eb0bf4f119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b9614dd2b14485adfea89287cd9602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57141a3861ca46ed8de45714039cfdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ece67cb77704d9188e3a012073003b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"google/gemma-2-2b-it\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3238364273d4f918555d473a3540f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7896 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d190072c98470898694fdb7c242a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/471 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = Dataset.from_pandas(train)\n",
    "dev_data = Dataset.from_pandas(dev)\n",
    "\n",
    "train_data = train_data.map(lambda samples: tokenizer(samples[\"prompt\"], padding=True, truncation=True), batched=True)\n",
    "dev_data = dev_data.map(lambda samples: tokenizer(samples[\"prompt\"], padding=True, truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tgkim\\anaconda3\\envs\\HATE\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "c:\\Users\\tgkim\\anaconda3\\envs\\HATE\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "c:\\Users\\tgkim\\anaconda3\\envs\\HATE\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "c:\\Users\\tgkim\\anaconda3\\envs\\HATE\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tgkim\\anaconda3\\envs\\HATE\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tgkim\\anaconda3\\envs\\HATE\\Lib\\site-packages\\accelerate\\accelerator.py:450: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665bca8eaaca40f9ba1d83d059aad4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1974 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012cc58653a2489f9a2096b925ab6f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5221846103668213, 'eval_runtime': 66.3397, 'eval_samples_per_second': 7.1, 'eval_steps_per_second': 0.889, 'epoch': 0.24}\n",
      "{'loss': 2.5864, 'grad_norm': 0.9098585844039917, 'learning_rate': 0.00015030549898167007, 'epoch': 0.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b431fc86a34350aae7e84d433a6d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4561800956726074, 'eval_runtime': 66.439, 'eval_samples_per_second': 7.089, 'eval_steps_per_second': 0.888, 'epoch': 0.48}\n",
      "{'loss': 2.3121, 'grad_norm': 0.8156091570854187, 'learning_rate': 9.938900203665988e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9805345e37e340f8bc3f9b2985ad49cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.423790454864502, 'eval_runtime': 66.224, 'eval_samples_per_second': 7.112, 'eval_steps_per_second': 0.891, 'epoch': 0.72}\n",
      "{'loss': 2.2523, 'grad_norm': 0.9182477593421936, 'learning_rate': 4.84725050916497e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6e574d452443838245c415e85d2ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.398855209350586, 'eval_runtime': 66.0471, 'eval_samples_per_second': 7.131, 'eval_steps_per_second': 0.893, 'epoch': 0.95}\n",
      "{'train_runtime': 3738.6003, 'train_samples_per_second': 2.112, 'train_steps_per_second': 0.528, 'train_loss': 2.345136802851127, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1974, training_loss=2.345136802851127, metrics={'train_runtime': 3738.6003, 'train_samples_per_second': 2.112, 'train_steps_per_second': 0.528, 'total_flos': 1.1505558862651392e+16, 'train_loss': 2.345136802851127, 'epoch': 1.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    target_modules=['o_proj', 'q_proj', 'up_proj', 'v_proj', 'k_proj', 'down_proj', 'gate_proj'],\n",
    "    lora_dropout=0.05,\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=dev_data,\n",
    "    dataset_text_field=\"prompt\",\n",
    "    peft_config=lora_config,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=10,\n",
    "        num_train_epochs=1,\n",
    "        learning_rate=2e-4,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        fp16=True,\n",
    "        save_strategy=\"epoch\",\n",
    "        eval_steps=471,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "    ),\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(query: str, model, tokenizer):\n",
    "\n",
    "  prompt_template = \"\"\"user\n",
    "  {query}\n",
    "  \n",
    "  model\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(query=query)\n",
    "  encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "  model_inputs = encodeds.to(\"cuda:0\")\n",
    "  generated_ids = model.generate(**model_inputs, do_sample=True, max_new_tokens=100, temperature=0.3)\n",
    "  decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "  return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "  17년도 아니고 27년이면 진짜 너무했다 이것이 사랑만으로 가능할수 있는지 도저히 납득이 가질 않는다\n",
      "  \n",
      "  model\n",
      "  model\n",
      "status: malicious comment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"17년도 아니고 27년이면 진짜 너무했다 이것이 사랑만으로 가능할수 있는지 도저히 납득이 가질 않는다\",\n",
    "                        model=trainer.model,\n",
    "                        tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "  문재앙 또뭘덥고 싶어서 ㄷㄷㄷ\n",
      "  \n",
      "  model\n",
      "  model\n",
      "status: malicious comment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"문재앙 또뭘덥고 싶어서 ㄷㄷㄷ\",\n",
    "                        model=trainer.model,\n",
    "                        tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = \"models\"\n",
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76d66d092b54c64bfb6743150fb0d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('malicious-comment-detector\\\\tokenizer_config.json',\n",
       " 'malicious-comment-detector\\\\special_tokens_map.json',\n",
       " 'malicious-comment-detector\\\\tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(model_id)  # \"googl/gemma-2b-it\"\n",
    "\n",
    "lora_model_id = \"C:/Users/tgkim/hate_detection/models\"\n",
    "lora_model = PeftModel.from_pretrained(base_model, lora_model_id)\n",
    "\n",
    "# 병합\n",
    "merged_model = lora_model.merge_and_unload()\n",
    "\n",
    "new_model_path = \"malicious-comment-detector\" \n",
    "merged_model.save_pretrained(new_model_path, safe_serialization=True)\n",
    "tokenizer.save_pretrained(new_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HATE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
